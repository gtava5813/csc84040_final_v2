{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "def format_recommendations(recommendations):\n",
    "    formatted = []\n",
    "    for rank, (item, score) in enumerate(recommendations, start=1):\n",
    "        formatted.append(f\"{rank}. {item} - Score: {score:.2f}\")\n",
    "    return formatted\n",
    "\n",
    "class SongRecommender:\n",
    "    def __init__(self):\n",
    "        self.lyrics_df = None\n",
    "        self.tfidf_similarity_matrix = None\n",
    "        self.encoder_embeddings = None\n",
    "        self.songs_and_artists = None\n",
    "        self.spotify_df = None\n",
    "        self.spotify_similarity_matrix = None\n",
    "        self.stop_words = self._get_stop_words()\n",
    "        self.drop_words = self._get_drop_words()\n",
    "        \n",
    "    def _get_drop_words(self):\n",
    "        drop_words = [\"remix\", \"mix)\", \"mix]\", \"(live\", \"[live\", \"live from\", \"recorded live\", \"version)\",\n",
    "                      \"version]\", \"edit)\", \"edit]\", \"edited)\", \"edited]\", \"demo)\", \"demo]\", \"the beyonce experience live\",\n",
    "                      \"homecoming live\", \"(acoustic\", \"[acoustic\", \"acoustic)\", \"acoustic]\"]\n",
    "        return '|'.join([re.escape(word) for word in drop_words])\n",
    "    \n",
    "    def _get_stop_words(self):\n",
    "        return [\"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\",\n",
    "                \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\", \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\",\n",
    "                \"are\", \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "                \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\",\n",
    "                \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\", \"elsewhere\", \"empty\", \"enough\",\n",
    "                \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\",\n",
    "                \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\",\n",
    "                \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "                \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\",\n",
    "                \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\",\n",
    "                \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\",\n",
    "                \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\",\n",
    "                \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "                \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\",\n",
    "                \"they\", \"thick\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\",\n",
    "                \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\",\n",
    "                \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\",\n",
    "                \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"remix\", \"mix\", \"produced\", \"producer\", \"edit\", \"oh\", \"ah\" \"ra\", \"la\", \"\\u200b\"]\n",
    "\n",
    "    def load_lyrics_data(self, data_folder):\n",
    "        \"\"\"\n",
    "        Load and preprocess lyrics data from CSV files\n",
    "        \n",
    "        Args:\n",
    "            data_folder (str): Path to folder containing CSV files\n",
    "        Returns:\n",
    "            self for method chaining\n",
    "        \"\"\"\n",
    "        lyrics_df = pd.DataFrame()\n",
    "        \n",
    "        for file in os.listdir(data_folder):\n",
    "            if file.endswith(\".csv\"):\n",
    "                # Read CSV file\n",
    "                df = pd.read_csv(os.path.join(data_folder, file))\n",
    "                \n",
    "                # Basic preprocessing\n",
    "                if 'Lyric' in df.columns and 'Artist' in df.columns and 'Title' in df.columns:\n",
    "                    # Drop rows with missing lyrics\n",
    "                    df = df.dropna(subset=[\"Lyric\"])\n",
    "                    \n",
    "                    # Create combined title and artist column\n",
    "                    df[\"Title and Artist\"] = df[\"Artist\"] + \" - \" + df[\"Title\"]\n",
    "                    \n",
    "                    # Select only needed columns\n",
    "                    df = df[[\"Title and Artist\", \"Lyric\"]]\n",
    "                    \n",
    "                    # Append to master dataframe\n",
    "                    lyrics_df = pd.concat([lyrics_df, df], ignore_index=True)\n",
    "        \n",
    "        if lyrics_df.empty:\n",
    "            raise ValueError(\"No valid lyrics data found in the specified folder\")\n",
    "            \n",
    "        self.lyrics_df = lyrics_df\n",
    "        self.songs_and_artists = lyrics_df['Title and Artist'].tolist()\n",
    "        return self\n",
    "\n",
    "    def _preprocess_lyrics_df(self, df):\n",
    "        df = df.dropna(subset=[\"Lyric\"])\n",
    "        df = df[~df[\"Title\"].str.contains(self.drop_words, case=False, na=False)]\n",
    "        df[\"Title and Artist\"] = df[\"Artist\"] + \" - \" + df[\"Title\"]\n",
    "        return df[[\"Title and Artist\", \"Lyric\"]]\n",
    "\n",
    "    def build_tfidf_model(self):\n",
    "        tfidf = TfidfVectorizer(\n",
    "            max_features=None,\n",
    "            stop_words=self.stop_words,\n",
    "            lowercase=True\n",
    "        )\n",
    "        tfidf_matrix = tfidf.fit_transform(self.lyrics_df['Lyric'])\n",
    "        self.tfidf_similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "        return self\n",
    "\n",
    "    def build_encoder_model(self, model_name='all-MiniLM-L6-v2'):\n",
    "        model = SentenceTransformer(model_name)\n",
    "        lyrics = self.lyrics_df['Lyric'].tolist()\n",
    "        self.encoder_embeddings = model.encode(lyrics, convert_to_tensor=True)\n",
    "        return self\n",
    "\n",
    "    def load_spotify_data(self, file_path):\n",
    "        features = ['danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                   'speechiness', 'acousticness', 'instrumentalness',\n",
    "                   'liveness', 'valence', 'tempo']\n",
    "        self.spotify_df = pd.read_csv(file_path)[['user_id', 'artistname', 'trackname'] + features]\n",
    "        self.spotify_similarity_matrix = cosine_similarity(self.spotify_df.iloc[:, 3:].values)\n",
    "        return self\n",
    "\n",
    "    def recommend_by_tfidf(self, query_song, top_n=5):\n",
    "        try:\n",
    "            idx = self.songs_and_artists.index(query_song)\n",
    "        except ValueError:\n",
    "            return f\"Song '{query_song}' not found in the dataset.\"\n",
    "        \n",
    "        similarity_scores = list(enumerate(self.tfidf_similarity_matrix[idx]))\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        similarity_scores = [s for s in similarity_scores if s[0] != idx]\n",
    "        return [(self.songs_and_artists[i], score) for i, score in similarity_scores[:top_n]]\n",
    "\n",
    "    def recommend_by_encoder(self, query_song, top_n=5):\n",
    "        try:\n",
    "            idx = self.songs_and_artists.index(query_song)\n",
    "        except ValueError:\n",
    "            return f\"Song '{query_song}' not found in the dataset.\"\n",
    "            \n",
    "        query_embedding = self.encoder_embeddings[idx]\n",
    "        similarity_scores = util.pytorch_cos_sim(query_embedding, self.encoder_embeddings)[0]\n",
    "        top_indices = similarity_scores.argsort(descending=True)[1:top_n+1]\n",
    "        return [(self.songs_and_artists[i], similarity_scores[i].item()) for i in top_indices]\n",
    "\n",
    "    def recommend_by_collaborative_filtering(self, query_song, n=5):\n",
    "        artist, track = query_song.split(\" - \", 1)\n",
    "        \n",
    "        target_song_index = self.spotify_df[\n",
    "            (self.spotify_df['artistname'] == artist) & \n",
    "            (self.spotify_df['trackname'] == track)\n",
    "        ].index.tolist()\n",
    "        \n",
    "        if not target_song_index:\n",
    "            print(f\"Song '{query_song}' not found in the dataset.\")\n",
    "            return []\n",
    "        \n",
    "        target_song_index = target_song_index[0]\n",
    "        similarity = self.spotify_similarity_matrix[target_song_index]\n",
    "        \n",
    "        recommendations = []\n",
    "        seen_songs = set()\n",
    "        \n",
    "        for idx, score in enumerate(similarity):\n",
    "            song_key = (self.spotify_df.iloc[idx]['artistname'], \n",
    "                    self.spotify_df.iloc[idx]['trackname'])\n",
    "            \n",
    "            if (idx != target_song_index and \n",
    "                song_key not in seen_songs):\n",
    "                recommendations.append((idx, *song_key, float(score)))\n",
    "                seen_songs.add(song_key)\n",
    "        \n",
    "        recommendations.sort(key=lambda x: x[3], reverse=True)\n",
    "        return [(artist+\" - \"+track, score) \n",
    "                for _, artist, track, score in recommendations[:n]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight Selection\n",
    "The weights should be chosen based on\n",
    "Collaborative filtering tends to provide better personalized recommendations\n",
    "TF-IDF is effective for content similarity but may miss novel recommendations\n",
    "Autoencoders can capture complex non-linear relationships\n",
    "A typical weighting could be:\n",
    "CF weight: 0.4 (highest weight due to better personalization)\n",
    "TF-IDF weight: 0.3\n",
    "Autoencoder weight: 0.3\n",
    "The weights can be tuned based on offline evaluation metrics like precision and recall at K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid(tfidf_recommendations,\n",
    "                     encoder_recommendations,\n",
    "                     cf_recommendations ,\n",
    "                     top_k=5,  \n",
    "                     weights = {'tfidf': 0.3,\n",
    "                                'encoder': 0.3,\n",
    "                                'collaborative': 0.4}): # weights to each model (can be tuned)\n",
    "    \n",
    "    # Normalize similarity scores to 0-1 range\n",
    "    def normalize_scores(recommendations):\n",
    "        scores = np.array([rec[1] for rec in recommendations])\n",
    "        min_score = scores.min()\n",
    "        max_score = scores.max()\n",
    "        normalized = (scores - min_score) / (max_score - min_score)\n",
    "        return [(rec[0], norm_score) for rec, norm_score in zip(recommendations, normalized)]\n",
    "\n",
    "    # Combine normalized scores\n",
    "    combined_scores = {}\n",
    "    for item, score in normalize_scores(tfidf_recommendations):\n",
    "        combined_scores[item] = weights['tfidf'] * score\n",
    "    \n",
    "    for item, score in normalize_scores(encoder_recommendations):\n",
    "        combined_scores[item] = combined_scores.get(item, 0) + weights['encoder'] * score\n",
    "        \n",
    "    for item, score in normalize_scores(cf_recommendations):\n",
    "        combined_scores[item] = combined_scores.get(item, 0) + weights['collaborative'] * score\n",
    "    \n",
    "    # Sort and return top K recommendations\n",
    "    sorted_items = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return format_recommendations(sorted_items[:top_k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Recommendations:\n",
      "- Coldplay - The Scientist (Love in Tokyo Version) (similarity: 0.98)\n",
      "- Coldplay - The Scientist (Live In Buenos Aires) (similarity: 0.67)\n",
      "- Eminem - The Monster (similarity: 0.27)\n",
      "- Drake - Signs (similarity: 0.22)\n",
      "- Drake - Easy (similarity: 0.19)\n",
      "\n",
      "Encoder Recommendations:\n",
      "- Coldplay - The Scientist (Love in Tokyo Version) (similarity: 1.00)\n",
      "- Coldplay - The Scientist (Live In Buenos Aires) (similarity: 0.92)\n",
      "- Justin Bieber - Break It Down (similarity: 0.59)\n",
      "- Coldplay - Trouble (Live @ Rockefeller Music Hall) (similarity: 0.57)\n",
      "- Coldplay - Trouble (Live at KCRW) (similarity: 0.57)\n",
      "\n",
      "Collaborative Filtering Recommendations:\n",
      "- Coldplay - The Scientist, 1.0000\n",
      "- Feist - The Limit To Your Love, 1.0000\n",
      "- The Magnetic Fields - I Wish I Had an Evil Twin, 1.0000\n",
      "- Sara Savery - Angel, 1.0000\n",
      "- Daft Punk - Doin' it Right, 1.0000\n",
      "\n",
      "Combined Normalized and Weighted Recommendations:\n",
      "1. Coldplay - The Scientist (Love in Tokyo Version) - Score: 0.60\n",
      "2. Coldplay - The Scientist (Live In Buenos Aires) - Score: 0.42\n",
      "3. Coldplay - The Scientist - Score: 0.40\n",
      "4. Feist - The Limit To Your Love - Score: 0.15\n",
      "5. Eminem - The Monster - Score: 0.03\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize recommender\n",
    "    recommender = SongRecommender()\n",
    "    \n",
    "    # Load and prepare data\n",
    "    recommender.load_lyrics_data(\"lyrics_dataset/csv\")\n",
    "    recommender.build_tfidf_model()\n",
    "    recommender.build_encoder_model()\n",
    "    recommender.load_spotify_data('spotify_data.csv')\n",
    "    \n",
    "    #Sample\n",
    "    query_song = \"Coldplay - The Scientist\"\n",
    "    \n",
    "    # Get recommendations using different methods\n",
    "    tfidf_recommendations = recommender.recommend_by_tfidf(query_song)\n",
    "    encoder_recommendations = recommender.recommend_by_encoder(query_song)\n",
    "    cf_recommendations = recommender.recommend_by_collaborative_filtering(query_song)\n",
    "    \n",
    "    print(\"TF-IDF Recommendations:\")\n",
    "    for song, score in tfidf_recommendations:\n",
    "        print(f\"- {song} (similarity: {score:.2f})\")\n",
    "        \n",
    "    print(\"\\nEncoder Recommendations:\")\n",
    "    for song, score in encoder_recommendations:\n",
    "        print(f\"- {song} (similarity: {score:.2f})\")\n",
    "        \n",
    "    print(\"\\nCollaborative Filtering Recommendations:\")\n",
    "    for song, score in cf_recommendations:\n",
    "        print(f\"- {song}, {score:.6f}\")\n",
    "        \n",
    "    final_recommendations = recommend_hybrid(tfidf_recommendations, encoder_recommendations, cf_recommendations)\n",
    "    print(\"\\nCombined Normalized and Weighted Recommendations:\")\n",
    "    for recommendation in final_recommendations:\n",
    "        print(recommendation)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc84040_final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
